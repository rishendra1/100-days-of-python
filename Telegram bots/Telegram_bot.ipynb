{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eFQ0qn7wodE",
        "outputId": "0aceb4cb-6713-4e42-80a4-1c0fce6cf116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/702.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/702.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m696.3/702.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.3/702.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q python-telegram-bot --upgrade\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2MTOvBsxS7y"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import google.generativeai as genai\n",
        "\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0U2WzDCxbTZ"
      },
      "outputs": [],
      "source": [
        "# Replace these with your actual credentials\n",
        "TOKEN = \"7797144430:AAEfNH4HPN_Vc-CkH8eOF0TWKljNM5tfVYI\"\n",
        "API_KEY = \"AIzaSyCwcjC6D6RMYpWXo7V2FHoMoPKBs4dFpC8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4_gFa51xrsN"
      },
      "outputs": [],
      "source": [
        "# Setup Gemini model\n",
        "genai.configure(api_key=API_KEY)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZnEkelGxwLT"
      },
      "outputs": [],
      "source": [
        "def generate_content(prompt: str) -> str:\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text if hasattr(response, \"text\") else \"❌ No response from model.\"\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdMbCWhtx2vX"
      },
      "outputs": [],
      "source": [
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    user_name = update.effective_user.first_name\n",
        "    greeting = f\"👋 Hello {user_name}! I am a AI-powered bot. Ask me anything!\"\n",
        "    await update.message.reply_text(greeting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2QmlG05yDMI"
      },
      "outputs": [],
      "source": [
        "async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    user_message = update.message.text\n",
        "    response_text = generate_content(user_message)\n",
        "    await update.message.reply_text(response_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6hPSNHjyIdT",
        "outputId": "9541a8a4-b29e-47bb-cc04-617676d08a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Bot is running...\n"
          ]
        }
      ],
      "source": [
        "async def main():\n",
        "    app = ApplicationBuilder().token(TOKEN).build()\n",
        "\n",
        "    # Add command and message handlers\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))\n",
        "\n",
        "    print(\"✅ Bot is running...\")\n",
        "    await app.run_polling()\n",
        "\n",
        "await main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}